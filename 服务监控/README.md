
* [监控系统原理](#监控系统原理)
  * [监控对象](#监控对象)
  * [监控指标](#监控指标)
  * [监控维度](#监控维度)
* [监控系统的构成](#监控系统的构成)
  * [数据采集](#数据采集)
    * [数据采集环节选型](#数据采集环节选型)
  * [数据传输](#数据传输)
    * [UDP传输](#UDP传输)
    * [Kafka传输](#Kafka传输)
    * [数据传输格式](#数据传输格式)
    * [数据传输环节选型](#数据传输环节选型)
  * [数据处理](#数据处理)
    * 数据聚合
      * [接⼝维度聚合](#接⼝维度聚合)
      * [机器维度聚合](#机器维度聚合)
    * [数据存储所选用的数据库](#数据存储所选用的数据库)
      * [索引数据库](#索引数据库)
      * [时序数据库](#时序数据库)
    * [数据处理环节选型](#数据处理环节选型)  
  * [数据展示](#数据展示)
* [监控系统选型](#监控系统选型)
  * [ELK集中式⽇志解决⽅案](#ELK集中式⽇志解决⽅案)
    * Elasticsearch
    * Logstash
    * Kibana
    * Beats---替代Logstash
  * [时序数据库解决⽅案](#时序数据库解决⽅案)
    * [Graphite](#Graphite)
    * [TICK](#TICK)
    * [Prometheus](#Prometheus)
    

---

# 监控系统原理

    ⼀旦服务消费者与服务提供者之间能够正常发起服务调⽤，你就需要对调⽤情况进⾏监控，以了解服务是否正常。通常来讲，服务监控主要包括四个流程。
  
    我们要对服务调⽤进⾏监控，⾸先要能收集到每⼀次调⽤的详细信息，包括调⽤的响应时间、调⽤是否成功、调⽤的发起者和接收者分别是谁，这个过程叫作数据采
    集。采集到数据之后，要把数据通过⼀定的⽅式传输给数据处理中⼼进⾏处理，这个过程叫作数据传输。数据传输过来后，数据处理中⼼再按照服务的维度进⾏聚合，
    计算出不同服务的请求量、响应时间以及错误率等信息并存储起来，这个过程叫作数据处理。最后再通过接⼝或者Dashboard的形式对外展示服务的调⽤情况，这
    个过程叫作数据展示
    
    可⻅，监控系统主要包括四个环节：数据采集、数据传输、数据处理和数据展示
    
## 监控对象

     对于微服务系统来说，监控对象可以分为四个层次，由上到下可归纳为：
     
     ⽤户端监控。通常是指业务直接对⽤户提供的功能的监控。以微博⾸⻚Feed为例，它向⽤户提供了聚合关注的所有⼈的微博并按照时间顺序浏览的功能，对
     ⾸⻚Feed功能的监控就属于⽤户端的监控。
     
     接⼝监控。通常是指业务提供的功能所依赖的具体RPC接⼝的监控。继续以微博⾸⻚Feed为例，这个功能依赖于⽤户关注了哪些⼈的关系服务，每个⼈发过
     哪些微博的微博列表服务，以及每条微博具体内容是什么的内容服务，对这⼏个服务的调⽤情况的监控就属于接⼝监控。
     
     资源监控。通常是指某个接⼝依赖的资源的监控。⽐如⽤户关注了哪些⼈的关系服务使⽤的是Redis来存储关注列表，对Redis的监控就属于资源监控。
     
     基础监控。通常是指对服务器本身的健康状况的监控。主要包括CPU利⽤率、内存使⽤量、I/O读写量、⽹卡带宽等。对服务器的基本监控也是必不可少
     的，因为服务器本身的健康状况也是影响服务本身的⼀个重要因素，⽐如服务器本身连接的⽹络交换机上联带宽被打满，会影响所有部署在这台服务器上的业务。
     
## 监控指标

通常有以下⼏个业务指标需要重点监控：


     请求量。请求量监控分为两个维度，⼀个是实时请求量，⼀个是统计请求量。实时请求量⽤QPS（Queries Per Second）即每秒查询次数来衡量，它反映了服
     务调⽤的实时变化情况。统计请求量⼀般⽤PV（Page View）即⼀段时间内⽤户的访问量来衡量，⽐如⼀天的PV代表了服务⼀天的请求量，通常⽤来统计报表。

     响应时间。⼤多数情况下，可以⽤⼀段时间内所有调⽤的平均耗时来反映请求的响应时间。但它只代表了请求的平均快慢情况，有时候我们更关⼼慢请求的数量。
     为此需要把响应时间划分为多个区间，⽐如0～10ms、10ms～50ms、50ms～100ms、100ms～500ms、500ms以上这五个区间，其中500ms以上这个区间内的请求数
     就代表了慢请求量，正常情况下，这个区间内的请求数应该接近于0；在出现问题时，这个区间内的请求数会⼤幅增加，可能平均耗时并不能反映出这⼀变化。除
     此之外，还可以从P90、P95、P99、P999⻆度来监控请求的响应时间，⽐如P99 = 500ms，意思是99%的请求响应时间在500ms以内，它代表了请求的服务质量，
     即SLA。

     错误率。错误率的监控通常⽤⼀段时间内调⽤失败的次数占调⽤总次数的⽐率来衡量，⽐如对于接⼝的错误率⼀般⽤接⼝返回错误码为503的⽐率来表示

## 监控维度
   
    全局维度。从整体⻆度监控对象的的请求量、平均耗时以及错误率，全局维度的监控⼀般是为了让你对监控对象的调⽤情况有个整体了解。

    分机房维度。⼀般为了业务的⾼可⽤性，服务通常部署在不⽌⼀个机房，因为不同机房地域的不同，同⼀个监控对象的各种指标可能会相差很⼤，所以需要深⼊
    到机房内部去了解。
    
    单机维度。即便是在同⼀个机房内部，可能由于采购年份和批次的不同，位于不同机器上的同⼀个监控对象的各种指标也会有很⼤差异。⼀般来说，新采购的机
    器通常由于成本更低，配置也更⾼，在同等请求量的情况下，可能表现出较⼤的性能差异，因此也需要从单机维度去监控同⼀个对象。
    
    时间维度。同⼀个监控对象，在每天的同⼀时刻各种指标通常也不会⼀样，这种差异要么是由业务变更导致，要么是运营活动导致。为了了解监控对象各种指标的
    变化，通常需要与⼀天前、⼀周前、⼀个⽉前，甚⾄三个⽉前做⽐较。
    
    核⼼维度。根据我的经验，业务上⼀般会依据重要性程度对监控对象进⾏分级，最简单的是分成核⼼业务和⾮核⼼业务。核⼼业务和⾮核⼼业务在部署上必须隔
    离，分开监控，这样才能对核⼼业务做重点保障。
    
# 监控系统的搭建    
   
    如何搭建⼀个监控系统，来完成上⾯这些监控功能呢？
    
## 数据采集

    通常有两种数据收集⽅式：
    
    服务主动上报，这种处理⽅式通过在业务代码或者服务框架⾥加⼊数据收集代码逻辑，在每⼀次服务调⽤完成后，主动上报服务的调⽤信息。

    代理收集，这种处理⽅式通过服务调⽤后把调⽤的详细信息记录到本地⽇志⽂件中，然后再通过代理去解析本地⽇志⽂件，然后再上报服务的调⽤信息。
    
    ⽆论哪种数据采集⽅式，⾸先要考虑的问题就是采样率，也就是采集数据的频率。采样率决定了监控的实时性与精确度，⼀般来说，采样率越⾼，监控的实时性就
    越⾼，精确度也越⾼。但采样对系统本身的性能也会有⼀定的影响，尤其是采集后的数据需要写到本地磁盘的时候，过⾼的采样率会导致系统写⼊磁盘的I/O过⾼，
    进⽽会影响到正常的服务调⽤。所以设置合理的采⽤率是数据采集的关键，最好是可以动态控制采样率，在系统⽐较空闲的时候加⼤采样率，追求监控的实时性与
    精确度；在系统负载⽐较⾼的时候减⼩采样率，追求监控的可⽤性与系统的稳定性。

### 数据采集环节选型

    ELK是通过在每台服务器上部署Beats代理来采集数据；
    
    Graphite本身没有收据采集组件，需要配合使⽤开源收据采集组件，⽐如StatsD；
    
    TICK使⽤了Telegraf作为数据采集组件；
    
    Prometheus通过jobs/exporters组件来获取StatsD等采集过来的metrics信息。



## 数据传输

    数据传输最常⽤的⽅式有两种：
    
### UDP传输
    
    这种处理⽅式是数据处理单元提供服务器的请求地址，数据采集后通过UDP协议与服务器建⽴连接，然后把数据发送过去。
    
### Kafka传输
    
    这种处理⽅式是数据采集后发送到指定的Topic，然后数据处理单元再订阅对应的Topic，就可以从Kafka消息队列中读取到对应的数据。

#### 数据传输格式

    ⼀般数据传输时采⽤的数据格式有两种:
    
    第一种方式： ⼆进制协议，最常⽤的就是PB对象，它的优点是⾼压缩⽐和⾼性能，可以减少传输带宽并且序列化和反序列化效率特别⾼。
    
    第二种方式： ⽂本协议，最常⽤的就是JSON字符串，它的优点是可读性好，但相⽐于PB对象，传输占⽤带宽⾼，并且解析性能也要差⼀些。

#### 数据传输环节选型

    ELK是Beats采集的数据传输给Logstash，经过Logstash清洗后再传输给Elasticsearch；
    
    Graphite是通过第三⽅采集组件采集的数据，传输给Carbon；
    
    TICK是Telegraf采集的数据，传输给InfluxDB；
    
    ⽽Prometheus是Prometheus Server隔⼀段时间定期去从jobs/exporters拉取数据。
    
    可⻅前三种都是采⽤“推数据”的⽅式，⽽Prometheus是采取拉数据的⽅式，因此Prometheus的解决⽅案对服务端的侵⼊最⼩，不需要在服务端部署数据采集代理。
    
## 数据处理

  数据处理是对收集来的原始数据进⾏聚合并存储，数据聚合通常有两个维度
  
### 数据聚合
  
#### 接⼝维度聚合
  
    这个维度是把实时收到的数据按照接⼝名维度实时聚合在⼀起，这样就可以得到每个接⼝的实时请求量、平均耗时等信息。

#### 机器维度聚合
    
    这个维度是把实时收到的数据按照调⽤的节点维度聚合在⼀起，这样就可以从单机维度去查看每个接⼝的实时请求量、平均耗时等信息。
  
### 数据存储所选用的数据库

#### 索引数据库

     ⽐如Elasticsearch，以倒排索引的数据结构存储，需要查询的时候，根据索引来查询。

#### 时序数据库

    ⽐如OpenTSDB，以时序序列数据的⽅式存储，查询的时候按照时序如1min、5min等维度来查询。


#### 数据处理环节选型

    ELK可以对⽇志的任意字段索引，适合多维度的数据查询，在存储时间序列数据⽅⾯与时间序列数据库相⽐会有额外的性能和存储开销
    
    Graphite通过Graphite-Web⽀持正则表达式匹配、sumSeries求和、alias给监控项重新命名等函数功能，同时还⽀持这些功能的组合

## 数据展示

  Graphite、TICK和Prometheus⾃带的展示功能都⽐较弱，界⾯也不好看，不过好在它们都⽀持Grafana来做数据展示。
  
  Grafana是⼀个开源的仪表盘⼯具，它⽀持多种数据源⽐如Graphite、InfluxDB、Prometheus以及Elasticsearch等。
  
  ELK采⽤了Kibana做数据展示，Kibana包含的数据展示功能⽐较强⼤，但只⽀持Elasticsearch，⽽且界⾯展示UI效果不如Grafana美观。

# 监控系统选型


     不同的监控系统实现⽅案，在这四个环节所使⽤的技术⽅案不同，适合的业务场景也不⼀样。
     
     从对实时性要求⻆度考虑，时间序列数据库的实时性要好于ELK，通常可以做到10s级别内的延迟，如果对实时性敏感的话，建议选择时间序列数据库解决⽅案。

     从使⽤的灵活性⻆度考虑，⼏种时间序列数据库的监控处理功能都要⽐ELK更加丰富，使⽤更灵活也更现代化。
     
     所以如果要搭建⼀套新的监控系统，我建议可以考虑采⽤Graphite、TICK或者Prometheus其中之⼀。不过Graphite还需要搭配数据采集系统⽐如StatsD
     或者Collectd使⽤，⽽且界⾯展示建议使⽤Grafana接⼊Graphite的数据源，它的效果要⽐GraphiteWeb本身提供的界⾯美观很多。TICK提供了完整的监控
     系统框架，包括从数据采集、数据传输、数据处理再到数据展示，不过在数据展示⽅⾯同样也建议⽤Grafana替换掉TICK默认的数据展示组件Chronograf，这
     样展示效果更好。Prometheus因为采⽤拉数据的⽅式，所以对业务的侵⼊性最⼩，⽐较适合Docker封装好的云原⽣应⽤，⽐如Kubernetes默认就采⽤了
     Prometheus作为监控系统

## ELK集中式⽇志解决⽅案
     
     第一种方案：
     
     Logstash->Elasticsearch->Kibana
     
     这种架构因为需要在各个服务器上部署Logstash来从不同的数据源收集数据，所以⽐较消耗CPU和内存资源，容易造成服务器性能下降,所以引入第二种方案
     
     第二种方案：
     
     Beats->Logstash->Elasticsearch->Kibana
     
     在Elasticsearch、Logstash、Kibana之外引⼊了Beats作为数据收集器。相⽐于Logstash，Beats所占系统的CPU和内存⼏乎可以忽略不计，可以安装在每
     台服务器上做轻量型代理，从成百上千或成千上万台机器向Logstash或者直接向Elasticsearch发送数据。
     
     Beats将收集到的数据发送到Logstash，经过Logstash解析、过滤后，再将数据发送到Elasticsearch，最后由Kibana展示
     
##  时序数据库解决⽅案


### Graphite
### TICK
### Prometheus 
     
     
     
